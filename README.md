
---

## ðŸ“š Retrieval-Augmented Generation (RAG) with Mistral 7B Instruct

This repository demonstrates how to build a **fully local RAG pipeline** using open-source models â€” with no reliance on OpenAI or closed APIs.

> ðŸ” Ask questions based on your own documents â€” PDFs, text files, datasets â€” and get accurate, source-grounded answers using `Mistral-7B-Instruct-v0.2`.

---

### ðŸš€ Features

* âœ… End-to-End RAG implementation
* ðŸ§  LLM: [Mistral 7B Instruct](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2)
* ðŸ”Ž Fast retrieval using FAISS vector search
* ðŸ§± Chunking, Embeddings, and Prompt Engineering with LangChain
* ðŸ”’ 100% Local â€” No cloud, No OpenAI key needed
* ðŸ“ Load data from TXT, Markdown, or JSONL (expandable to PDF/CSV)

---

### ðŸ› ï¸ Tech Stack

* `LangChain`
* `transformers` (HuggingFace)
* `sentence-transformers`
* `FAISS`
* `datasets`
* `bitsandbytes` (for 4-bit quantization)

---

### ðŸ“¦ Installation

```bash
git clone https://github.com/yourusername/rag-mistral7b.git
cd rag-mistral7b

# Install dependencies
pip install -r requirements.txt

# Optional: Use virtualenv
python -m venv venv
source venv/bin/activate
```

---

### ðŸ”§ Usage

#### 1. **Set HuggingFace Token (for gated model)**

```bash
huggingface-cli login
```

Make sure you have accepted access to [`Mistral-7B-Instruct-v0.2`](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2).

#### 2. **Prepare your data**

Place your documents inside the `data/` folder (e.g., `.txt`, `.md`, `.jsonl`)

#### 3. **Run the pipeline**

```bash
python main.py
```

This will:

* Load & split your documents into chunks
* Embed them with `sentence-transformers`
* Store them in a FAISS index
* Accept a user query
* Retrieve relevant chunks and generate an answer using Mistral 7B

---

### ðŸ§  Architecture Overview

```text
[Documents] â†’ [Chunking] â†’ [Embedding] â†’ [FAISS Vector DB]
                                  â†‘
                                  â†“
                            [Retriever]
                                  â†‘
                            [Query Input]
                                  â†“
                    [RAG Prompt + Mistral 7B Output]
```

---

### ðŸ“ Example Output

**Input:**

> "What is the refund policy of the company?"

**Output:**

> "The company offers a 30-day refund policy. If you're not satisfied, you can request a refund within that period."

---

### âœ… Future Improvements

* Add support for PDF, CSV, and Word documents
* Serve via API (FastAPI) or Chatbot UI
* Add streaming support and memory for conversations
* Switch between different embedding models

---

### ðŸ™Œ Acknowledgements

* [Mistral AI](https://huggingface.co/mistralai)
* [LangChain](https://github.com/langchain-ai/langchain)
* [HuggingFace Transformers](https://huggingface.co/docs/transformers/index)
* [FAISS](https://github.com/facebookresearch/faiss)

---

### ðŸ“„ License

MIT License. Feel free to use and modify.

---
